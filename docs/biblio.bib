@misc{chatgpt,
  url     = {https://openai.com/index/chatgpt},
  journal = {Introducing ChatGPT},
  author  = {OpenAI},
  year    = {2022},
  month   = {Nov}
}

@misc{attention_is_all_you_need,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2023},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{model_sizes,
  title   = {Large language models: A new Moore’s Law?},
  url     = {https://huggingface.co/blog/large-language-models},
  journal = {Hugging Face – The AI community building the future.},
  author  = {Simon, Julien},
  year    = {2021},
  month   = {Oct}
}

@inproceedings{lei-etal-2016-rationalizing,
  title     = {Rationalizing Neural Predictions},
  author    = {Lei, Tao  and
               Barzilay, Regina  and
               Jaakkola, Tommi},
  editor    = {Su, Jian  and
               Duh, Kevin  and
               Carreras, Xavier},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D16-1011},
  doi       = {10.18653/v1/D16-1011},
  pages     = {107--117}
}

@misc{strobl2024formal,
  title         = {What Formal Languages Can Transformers Express? A Survey},
  author        = {Lena Strobl and William Merrill and Gail Weiss and David Chiang and Dana Angluin},
  year          = {2024},
  eprint        = {2311.00208},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@incollection{context-free-chomsky,
  title     = {The Algebraic Theory of Context-Free Languages*},
  editor    = {P. Braffort and D. Hirschberg},
  series    = {Studies in Logic and the Foundations of Mathematics},
  publisher = {Elsevier},
  volume    = {35},
  pages     = {118-161},
  year      = {1963},
  booktitle = {Computer Programming and Formal Systems},
  issn      = {0049-237X},
  doi       = {https://doi.org/10.1016/S0049-237X(08)72023-8},
  url       = {https://www.sciencedirect.com/science/article/pii/S0049237X08720238},
  author    = {N. Chomsky and M.P. Schützenberger},
  abstract  = {Publisher Summary
               This chapter discusses the several classes of sentence-generating devices that are closely related, in various ways, to the grammars of both natural languages and artificial languages of various kinds. By a language it simply mean a set of strings in some finite set V of symbols called the vocabulary of the language. By a grammar a set of rules that give a recursive enumeration of the strings belonging to the language. It can be said that the grammar generates these strings. The chapter discusses the aspect of the structural description of a sentence, namely, its subdivision into phrases belonging to various categories. A major concern of the general theory of natural languages is to define the class of possible strings; the class of possible grammars; the class of possible structural descriptions; a procedure for assigning structural descriptions to sentences, given a grammar; and to do all of this in such a way that the structural description assigned to a sentence by the grammar of a natural language will provide the basis for explaining how a speaker of this language would understand this sentence.}
}

@article{chomsky-hierarchy,
  title    = {On certain formal properties of grammars},
  journal  = {Information and Control},
  volume   = {2},
  number   = {2},
  pages    = {137-167},
  year     = {1959},
  issn     = {0019-9958},
  doi      = {https://doi.org/10.1016/S0019-9958(59)90362-6},
  url      = {https://www.sciencedirect.com/science/article/pii/S0019995859903626},
  author   = {Noam Chomsky},
  abstract = {A grammar can be regarded as a device that enumerates the sentences of a language. We study a sequence of restrictions that limit grammars first to Turing machines, then to two types of system from which a phrase structure description of the generated language can be drawn, and finally to finite state Markov sources (finite automata). These restrictions are shown to be increasingly heavy in the sense that the languages that can be generated by grammars meeting a given restriction constitute a proper subset of those that can be generated by grammars meeting the preceding restriction. Various formulations of phrase structure description are considered, and the source of their excess generative power over finite state sources is investigated in greater detail.}
}

@article{attention-tc,
  author  = {Jorge Pérez and Pablo Barceló and Javier Marinkovic},
  title   = {Attention is Turing-Complete},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {75},
  pages   = {1--35},
  url     = {http://jmlr.org/papers/v22/20-302.html}
}

@book{hopcroft-automata,
  author    = {Hopcroft, John E. and Motwani, Rajeev and Ullman, Jeffrey D.},
  title     = {Introduction to Automata Theory,  Languages, and Computation (3rd Edition)},
  year      = {2006},
  isbn      = {0321462254},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  address   = {USA}
}

@book{leeuwen-cfg,
  editor    = {Jan van Leeuwen},
  title     = {Handbook of Theoretical Computer Science, Volume {B:} Formal Models
               and Semantics},
  publisher = {Elsevier and {MIT} Press},
  year      = {1990},
  url       = {https://www.sciencedirect.com/book/9780444880741/formal-models-and-semantics},
  isbn      = {0-444-88074-7},
  timestamp = {Tue, 06 Aug 2019 09:45:21 +0200},
  biburl    = {https://dblp.org/rec/books/el/Leeuwen90a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{rozenberg1997handbook,
  title     = {Handbook of Formal Languages: Volume 1. Word, Language, Grammar},
  author    = {Rozenberg, G. and Salomaa, A.},
  isbn      = {9783540604204},
  lccn      = {lc96047134},
  series    = {Handbook of Formal Languages},
  url       = {https://books.google.com.uy/books?id=yQ59ojndUt4C},
  year      = {1997},
  publisher = {Springer}
}

@misc{badhanau-attn,
      title={Neural Machine Translation by Jointly Learning to Align and Translate},
      author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
      year={2016},
      eprint={1409.0473},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1409.0473},
}

@misc{bounded-hierarchical-languages,
      title={Self-Attention Networks Can Process Bounded Hierarchical Languages},
      author={Shunyu Yao and Binghui Peng and Christos Papadimitriou and Karthik Narasimhan},
      year={2023},
      eprint={2105.11115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2105.11115},
}

@misc{bhattamistra-transformers-formal-languages,
      title={On the Ability and Limitations of Transformers to Recognize Formal Languages},
      author={Satwik Bhattamishra and Kabir Ahuja and Navin Goyal},
      year={2020},
      eprint={2009.11264v2},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.11264}
}

@misc{mech_interp, 
    title={Toy Models of Superposition}, 
    url={https://transformer-circuits.pub/2022/toy_model/index.html}, 
    author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and et al.}, 
    year={2022}, month={Sep}
} 

@misc{layernorm,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1607.06450}, 
}

@misc{pytorch-max,
	author = {{Pytorch Foundation} and {Pytorch Contributors}},
	title = {torch.max; {P}y{T}orch 2.4 documentation - pytorch.org},
	url = {https://pytorch.org/docs/stable/generated/torch.max.html},
	year = {2023},
}

@software{poetry,
author = {Eustace, Sébastien and {The Poetry contributors}},
license = {MIT},
title = {{Poetry: Python packaging and dependency management made easy}},
url = {https://github.com/python-poetry/poetry}
}

@software{typer,
author = {Ramírez, Sebastián},
license = {MIT},
title = {{Typer}},
url = {https://github.com/fastapi/typer}
}

@inproceedings{pytorch,
author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and Luk, CK and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Suo, Michael and Tillet, Phil and Wang, Eikan and Wang, Xiaodong and Wen, William and Zhang, Shunting and Zhao, Xu and Zhou, Keren and Zou, Richard and Mathews, Ajit and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
booktitle = {29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)},
doi = {10.1145/3620665.3640366},
month = apr,
publisher = {ACM},
title = {{PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation}},
url = {https://pytorch.org/assets/pytorch2-2.pdf},
year = {2024}
}