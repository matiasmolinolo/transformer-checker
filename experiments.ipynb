{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dyck_k_generator import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "elif device == \"cuda:0\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = \"\".join(\n",
    "    [\"\".join((key, value)) for key, value in list(constants.BRACKETS.items())[:k]]\n",
    ")\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import DyckLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 samples from data/dyck-1_50000-samples_80-len_p05.jsonl\n"
     ]
    }
   ],
   "source": [
    "dataset = DyckLanguageDataset(\"data/dyck-1_50000-samples_80-len_p05.jsonl\", VOCAB).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Transformer + BERTViz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.hooked_transformer import (\n",
    "    TransformerClassifier,\n",
    "    TransformerClassifierConfig,\n",
    "    pad_token_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = TransformerClassifierConfig(\n",
    "    vocab_size=len(VOCAB), d_model=128, n_heads=1, dim_ff=256, n_layers=1, n_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerClassifier(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn): ScaledDotProductAttention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn): ScaledDotProductAttention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb59a85eeda54d03925978cd9ed0914e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7017724961042404, Accuracy: 49.75%\n",
      "Epoch: 1, Loss: 0.7044054061174393, Accuracy: 49.15625%\n",
      "Epoch: 1, Loss: 0.7032073503732681, Accuracy: 49.375%\n",
      "Epoch: 1, Loss: 0.7008068627119064, Accuracy: 49.578125%\n",
      "Epoch: 1, Loss: 0.6968782502412796, Accuracy: 50.1375%\n",
      "Epoch: 1, Loss: 0.6992424154281616, Accuracy: 50.0625%\n",
      "Epoch: 1, Loss: 0.6996126294136047, Accuracy: 50.089285714285715%\n",
      "Epoch: 1, Loss: 0.6993944478034974, Accuracy: 49.703125%\n",
      "Epoch: 1, Loss: 0.695627635717392, Accuracy: 49.791666666666664%\n",
      "Epoch: 1, Loss: 0.6995605140924454, Accuracy: 49.8%\n",
      "Epoch: 1, Loss: 0.6998740947246551, Accuracy: 49.64772727272727%\n",
      "Epoch: 1, Loss: 0.6983847111463547, Accuracy: 49.583333333333336%\n",
      "Epoch: 1, Loss: 0.6933022540807724, Accuracy: 49.75961538461539%\n",
      "Epoch: 1, Loss: 0.6937030464410782, Accuracy: 49.875%\n",
      "Epoch: 1, Loss: 0.6963864505290985, Accuracy: 49.77916666666667%\n",
      "Epoch: 1, Loss: 0.6943097025156021, Accuracy: 49.94140625%\n",
      "Epoch: 1, Loss: 0.6951315319538116, Accuracy: 49.904411764705884%\n",
      "Epoch: 1, Loss: 0.6905259078741074, Accuracy: 50.12152777777777%\n",
      "Epoch: 1, Loss: 0.6926082646846772, Accuracy: 50.19736842105264%\n",
      "Epoch: 1, Loss: 0.695460050702095, Accuracy: 50.2%\n",
      "Epoch: 1, Loss: 0.6939663028717041, Accuracy: 50.2470238095238%\n",
      "Epoch: 1, Loss: 0.6950419485569, Accuracy: 50.227272727272734%\n",
      "Epoch: 1, Loss: 0.6962656480073929, Accuracy: 50.1929347826087%\n",
      "Epoch: 1, Loss: 0.6946499562263488, Accuracy: 50.20312500000001%\n",
      "Epoch: 1, Loss: 0.6931640613079071, Accuracy: 50.237500000000004%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea5fce5226f436e99e358b3b1dd8ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.6949646145105361, Accuracy: 49.75%\n",
      "Epoch: 2, Loss: 0.6913996458053588, Accuracy: 50.84375%\n",
      "Epoch: 2, Loss: 0.693353419303894, Accuracy: 50.4375%\n",
      "Epoch: 2, Loss: 0.6923092359304428, Accuracy: 50.171875%\n",
      "Epoch: 2, Loss: 0.6899596041440964, Accuracy: 49.925000000000004%\n",
      "Epoch: 2, Loss: 0.6915988171100617, Accuracy: 50.15625%\n",
      "Epoch: 2, Loss: 0.6907907122373581, Accuracy: 50.205357142857146%\n",
      "Epoch: 2, Loss: 0.6954142928123475, Accuracy: 50.109375%\n",
      "Epoch: 2, Loss: 0.6890650510787963, Accuracy: 50.48611111111111%\n",
      "Epoch: 2, Loss: 0.6871444857120514, Accuracy: 50.80625%\n",
      "Epoch: 2, Loss: 0.6911111283302307, Accuracy: 50.80681818181818%\n",
      "Epoch: 2, Loss: 0.6935140496492386, Accuracy: 50.67708333333333%\n",
      "Epoch: 2, Loss: 0.6894390892982483, Accuracy: 50.92307692307693%\n",
      "Epoch: 2, Loss: 0.6904855871200561, Accuracy: 51.03124999999999%\n",
      "Epoch: 2, Loss: 0.6845996057987214, Accuracy: 51.05833333333333%\n",
      "Epoch: 2, Loss: 0.6882716172933578, Accuracy: 50.81250000000001%\n",
      "Epoch: 2, Loss: 0.6933062726259231, Accuracy: 50.639705882352935%\n",
      "Epoch: 2, Loss: 0.6911657810211181, Accuracy: 50.62152777777777%\n",
      "Epoch: 2, Loss: 0.6909881460666657, Accuracy: 50.65460526315789%\n",
      "Epoch: 2, Loss: 0.6772774428129196, Accuracy: 50.809375%\n",
      "Epoch: 2, Loss: 0.6381278532743454, Accuracy: 51.19047619047619%\n",
      "Epoch: 2, Loss: 0.5418152013421058, Accuracy: 52.16193181818182%\n",
      "Epoch: 2, Loss: 0.44419199630618095, Accuracy: 53.48913043478261%\n",
      "Epoch: 2, Loss: 0.2998763782531023, Accuracy: 55.033854166666664%\n",
      "Epoch: 2, Loss: 0.3470984288305044, Accuracy: 56.3125%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07443642f9894f22b8e2867b82fd55e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.24446938287466766, Accuracy: 91.8125%\n",
      "Epoch: 3, Loss: 0.22315522577613592, Accuracy: 92.0625%\n",
      "Epoch: 3, Loss: 0.21963400296866895, Accuracy: 92.45833333333333%\n",
      "Epoch: 3, Loss: 0.19216226940974593, Accuracy: 92.890625%\n",
      "Epoch: 3, Loss: 0.2179800122976303, Accuracy: 92.83749999999999%\n",
      "Epoch: 3, Loss: 0.21520473128184675, Accuracy: 92.98958333333334%\n",
      "Epoch: 3, Loss: 0.19619207007810474, Accuracy: 93.13392857142857%\n",
      "Epoch: 3, Loss: 0.16579739172011615, Accuracy: 93.40625%\n",
      "Epoch: 3, Loss: 0.14749830724671484, Accuracy: 93.6875%\n",
      "Epoch: 3, Loss: 0.17655942188575863, Accuracy: 93.78125%\n",
      "Epoch: 3, Loss: 0.1689830768853426, Accuracy: 93.91477272727272%\n",
      "Epoch: 3, Loss: 0.17367743355222046, Accuracy: 94.0%\n",
      "Epoch: 3, Loss: 0.1889447011332959, Accuracy: 93.98557692307692%\n",
      "Epoch: 3, Loss: 0.24123542699962855, Accuracy: 93.86160714285714%\n",
      "Epoch: 3, Loss: 0.1733201264217496, Accuracy: 93.90416666666667%\n",
      "Epoch: 3, Loss: 0.15850066802464424, Accuracy: 93.9921875%\n",
      "Epoch: 3, Loss: 0.14097894933074712, Accuracy: 94.11029411764706%\n",
      "Epoch: 3, Loss: 0.17661419562995434, Accuracy: 94.11805555555556%\n",
      "Epoch: 3, Loss: 0.15015825467184185, Accuracy: 94.21052631578948%\n",
      "Epoch: 3, Loss: 0.1182512143626809, Accuracy: 94.346875%\n",
      "Epoch: 3, Loss: 0.2713602081406862, Accuracy: 94.21428571428572%\n",
      "Epoch: 3, Loss: 0.18201605418697, Accuracy: 94.23011363636363%\n",
      "Epoch: 3, Loss: 0.16858779454603792, Accuracy: 94.26086956521739%\n",
      "Epoch: 3, Loss: 0.12029939555563032, Accuracy: 94.3671875%\n",
      "Epoch: 3, Loss: 0.20376673023216427, Accuracy: 94.32000000000001%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34d252363e54991b5ee4911c70a1e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.16679189823567867, Accuracy: 94.8125%\n",
      "Epoch: 4, Loss: 0.15674508384428917, Accuracy: 95.1875%\n",
      "Epoch: 4, Loss: 0.16673563987948, Accuracy: 95.0625%\n",
      "Epoch: 4, Loss: 0.1798365420103073, Accuracy: 94.828125%\n",
      "Epoch: 4, Loss: 0.14909384472295642, Accuracy: 95.025%\n",
      "Epoch: 4, Loss: 0.1713946695625782, Accuracy: 94.91666666666667%\n",
      "Epoch: 4, Loss: 0.11760223999619485, Accuracy: 95.23214285714286%\n",
      "Epoch: 4, Loss: 0.14479970352724195, Accuracy: 95.3046875%\n",
      "Epoch: 4, Loss: 0.14286796184256673, Accuracy: 95.36111111111111%\n",
      "Epoch: 4, Loss: 0.14571362089365722, Accuracy: 95.43125%\n",
      "Epoch: 4, Loss: 0.18372678393498063, Accuracy: 95.29545454545455%\n",
      "Epoch: 4, Loss: 0.17082225690595806, Accuracy: 95.23958333333333%\n",
      "Epoch: 4, Loss: 0.15746333418413996, Accuracy: 95.23557692307692%\n",
      "Epoch: 4, Loss: 0.16973500283434986, Accuracy: 95.19196428571428%\n",
      "Epoch: 4, Loss: 0.16200049759820104, Accuracy: 95.19999999999999%\n",
      "Epoch: 4, Loss: 0.11911892343312502, Accuracy: 95.3125%\n",
      "Epoch: 4, Loss: 0.14685526851564645, Accuracy: 95.34558823529412%\n",
      "Epoch: 4, Loss: 0.1433349731983617, Accuracy: 95.38888888888889%\n",
      "Epoch: 4, Loss: 0.1944659641664475, Accuracy: 95.31907894736842%\n",
      "Epoch: 4, Loss: 0.15181339962407947, Accuracy: 95.31875%\n",
      "Epoch: 4, Loss: 0.1230512155778706, Accuracy: 95.39583333333333%\n",
      "Epoch: 4, Loss: 0.15576300758868455, Accuracy: 95.39204545454545%\n",
      "Epoch: 4, Loss: 0.15331456357613205, Accuracy: 95.40217391304347%\n",
      "Epoch: 4, Loss: 0.15432197976857423, Accuracy: 95.4140625%\n",
      "Epoch: 4, Loss: 0.14258915770798922, Accuracy: 95.44%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd6469b1c3b4a4b9553846d8ebe0a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.1450021503958851, Accuracy: 95.75%\n",
      "Epoch: 5, Loss: 0.1507642393000424, Accuracy: 95.625%\n",
      "Epoch: 5, Loss: 0.17222867670468986, Accuracy: 95.3125%\n",
      "Epoch: 5, Loss: 0.1598280956968665, Accuracy: 95.265625%\n",
      "Epoch: 5, Loss: 0.15093883414752782, Accuracy: 95.2375%\n",
      "Epoch: 5, Loss: 0.18484525859355927, Accuracy: 95.0625%\n",
      "Epoch: 5, Loss: 0.16197976237162948, Accuracy: 95.02678571428571%\n",
      "Epoch: 5, Loss: 0.16393272333778441, Accuracy: 95.046875%\n",
      "Epoch: 5, Loss: 0.15040372792631387, Accuracy: 95.08333333333333%\n",
      "Epoch: 5, Loss: 0.13091083045117557, Accuracy: 95.2125%\n",
      "Epoch: 5, Loss: 0.16455965518951415, Accuracy: 95.19886363636364%\n",
      "Epoch: 5, Loss: 0.14908032700419427, Accuracy: 95.24479166666666%\n",
      "Epoch: 5, Loss: 0.1548014102317393, Accuracy: 95.2548076923077%\n",
      "Epoch: 5, Loss: 0.1396953641809523, Accuracy: 95.32142857142857%\n",
      "Epoch: 5, Loss: 0.18583439560607076, Accuracy: 95.21666666666667%\n",
      "Epoch: 5, Loss: 0.16235683726146818, Accuracy: 95.1953125%\n",
      "Epoch: 5, Loss: 0.21560352394357324, Accuracy: 95.04779411764706%\n",
      "Epoch: 5, Loss: 0.16404517201706767, Accuracy: 95.05208333333334%\n",
      "Epoch: 5, Loss: 0.12686475642956793, Accuracy: 95.13486842105263%\n",
      "Epoch: 5, Loss: 0.14627455037087203, Accuracy: 95.171875%\n",
      "Epoch: 5, Loss: 0.1644602508470416, Accuracy: 95.14880952380952%\n",
      "Epoch: 5, Loss: 0.1426224110927433, Accuracy: 95.17329545454545%\n",
      "Epoch: 5, Loss: 0.15182293530553578, Accuracy: 95.19021739130434%\n",
      "Epoch: 5, Loss: 0.12922593230381607, Accuracy: 95.23958333333333%\n",
      "Epoch: 5, Loss: 0.1580241878516972, Accuracy: 95.2325%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(dl)):\n",
    "        _, labels, tokens = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        tokens = tokens.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mask = pad_token_mask(tokens)\n",
    "        outputs = model(tokens, mask=None)\n",
    "        loss = crit(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # Count correct predictions\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = (total_correct / total_samples) * 100\n",
    "        # calculate accuracy\n",
    "        if i % 100 == 99:\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1}, Loss: {running_loss / 100}, Accuracy: {accuracy}%\"\n",
    "            )\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn): ScaledDotProductAttention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 96.19%\n",
      "Average loss on the test data: 0.1328\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():  # Important to use torch.no_grad() to save memory and computations\n",
    "    for batch in test_dl:\n",
    "        _, labels, tokens = batch\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        tokens = tokens.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(tokens)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Convert outputs probabilities to predicted class (0 or 1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Count total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_loss = total_loss / len(test_dl)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"Accuracy of the model on the test data: {accuracy:.2f}%\")\n",
    "print(f\"Average loss on the test data: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
