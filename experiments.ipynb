{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dyck_k_generator import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "elif device == \"cuda:0\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = \"\".join(\n",
    "    [\"\".join((key, value)) for key, value in list(constants.BRACKETS.items())[:k]]\n",
    ")\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.dataset import DyckLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 samples from data/dyck-1_50000-samples_80-len_p05.jsonl\n"
     ]
    }
   ],
   "source": [
    "dataset = DyckLanguageDataset(\"data/dyck-1_50000-samples_80-len_p05.jsonl\", VOCAB).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Transformer + BERTViz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.hooked_transformer import (\n",
    "    TransformerClassifier,\n",
    "    TransformerClassifierConfig,\n",
    "    pad_token_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = TransformerClassifierConfig(\n",
    "    vocab_size=len(VOCAB), d_model=128, n_heads=1, dim_ff=256, n_layers=1, n_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerClassifier(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn): ScaledDotProductAttention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn): ScaledDotProductAttention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b67c67fab3a437b9028a8b28495e653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.1252574836742133, Accuracy: 96.5%\n",
      "Epoch: 1, Loss: 0.1612290677241981, Accuracy: 95.875%\n",
      "Epoch: 1, Loss: 0.1418215196020901, Accuracy: 95.9375%\n",
      "Epoch: 1, Loss: 0.14777467732317745, Accuracy: 95.90625%\n",
      "Epoch: 1, Loss: 0.1371242884453386, Accuracy: 95.975%\n",
      "Epoch: 1, Loss: 0.15617146665230394, Accuracy: 95.89583333333334%\n",
      "Epoch: 1, Loss: 0.11831501048058271, Accuracy: 96.03571428571429%\n",
      "Epoch: 1, Loss: 0.298379271607846, Accuracy: 95.25%\n",
      "Epoch: 1, Loss: 0.18436361694708467, Accuracy: 95.11111111111111%\n",
      "Epoch: 1, Loss: 0.14364695316180587, Accuracy: 95.19375%\n",
      "Epoch: 1, Loss: 0.1246203856356442, Accuracy: 95.31818181818181%\n",
      "Epoch: 1, Loss: 0.14554212672635913, Accuracy: 95.38541666666667%\n",
      "Epoch: 1, Loss: 0.1512499910220504, Accuracy: 95.41826923076923%\n",
      "Epoch: 1, Loss: 0.12865840824320912, Accuracy: 95.48660714285714%\n",
      "Epoch: 1, Loss: 0.1189960309676826, Accuracy: 95.57916666666667%\n",
      "Epoch: 1, Loss: 0.15177488762885333, Accuracy: 95.59765625%\n",
      "Epoch: 1, Loss: 0.15631270974874498, Accuracy: 95.5735294117647%\n",
      "Epoch: 1, Loss: 0.1918780156970024, Accuracy: 95.47222222222223%\n",
      "Epoch: 1, Loss: 0.1441778140515089, Accuracy: 95.48026315789474%\n",
      "Epoch: 1, Loss: 0.18381363451480864, Accuracy: 95.403125%\n",
      "Epoch: 1, Loss: 0.1531914203800261, Accuracy: 95.41071428571428%\n",
      "Epoch: 1, Loss: 0.11654686141759157, Accuracy: 95.48295454545455%\n",
      "Epoch: 1, Loss: 0.1204215078894049, Accuracy: 95.54076086956522%\n",
      "Epoch: 1, Loss: 0.12472338125109672, Accuracy: 95.5859375%\n",
      "Epoch: 1, Loss: 0.11157075061462819, Accuracy: 95.6425%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f45dec368d4352b922198643d214e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.19645076582208276, Accuracy: 93.3125%\n",
      "Epoch: 2, Loss: 0.16730761169455946, Accuracy: 93.96875%\n",
      "Epoch: 2, Loss: 0.15643150942400097, Accuracy: 94.41666666666667%\n",
      "Epoch: 2, Loss: 0.13075309737585486, Accuracy: 94.921875%\n",
      "Epoch: 2, Loss: 0.13694046798162163, Accuracy: 95.16250000000001%\n",
      "Epoch: 2, Loss: 0.14205553133040666, Accuracy: 95.26041666666667%\n",
      "Epoch: 2, Loss: 0.14888643636368215, Accuracy: 95.3125%\n",
      "Epoch: 2, Loss: 0.1439134368300438, Accuracy: 95.3984375%\n",
      "Epoch: 2, Loss: 0.11215221283026039, Accuracy: 95.59722222222223%\n",
      "Epoch: 2, Loss: 0.1628236943297088, Accuracy: 95.56875000000001%\n",
      "Epoch: 2, Loss: 0.15365199402906002, Accuracy: 95.56818181818181%\n",
      "Epoch: 2, Loss: 0.12017332941293717, Accuracy: 95.67708333333333%\n",
      "Epoch: 2, Loss: 0.13315392060205342, Accuracy: 95.73557692307692%\n",
      "Epoch: 2, Loss: 0.1207619784027338, Accuracy: 95.80803571428571%\n",
      "Epoch: 2, Loss: 0.1377338131237775, Accuracy: 95.83333333333334%\n",
      "Epoch: 2, Loss: 0.1470795820467174, Accuracy: 95.82421875%\n",
      "Epoch: 2, Loss: 0.1263056898675859, Accuracy: 95.87132352941177%\n",
      "Epoch: 2, Loss: 0.11331594273447991, Accuracy: 95.9375%\n",
      "Epoch: 2, Loss: 0.1587127230875194, Accuracy: 95.89473684210526%\n",
      "Epoch: 2, Loss: 0.13151353704743088, Accuracy: 95.921875%\n",
      "Epoch: 2, Loss: 0.11717393635772169, Accuracy: 95.9672619047619%\n",
      "Epoch: 2, Loss: 0.24348492617718875, Accuracy: 95.79829545454545%\n",
      "Epoch: 2, Loss: 0.16485052717849613, Accuracy: 95.75271739130434%\n",
      "Epoch: 2, Loss: 0.16131146347150208, Accuracy: 95.71875%\n",
      "Epoch: 2, Loss: 0.1429325038101524, Accuracy: 95.7225%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f56129eba8b424c9ec09719b2c076d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.1215998753439635, Accuracy: 96.5625%\n",
      "Epoch: 3, Loss: 0.18043030761182308, Accuracy: 95.4375%\n",
      "Epoch: 3, Loss: 0.14169106606394052, Accuracy: 95.64583333333333%\n",
      "Epoch: 3, Loss: 0.13094644121825694, Accuracy: 95.84375%\n",
      "Epoch: 3, Loss: 0.1352026926353574, Accuracy: 95.9125%\n",
      "Epoch: 3, Loss: 0.13988829903304578, Accuracy: 95.96875%\n",
      "Epoch: 3, Loss: 0.14037946834228932, Accuracy: 95.98214285714286%\n",
      "Epoch: 3, Loss: 0.1800075493659824, Accuracy: 95.78125%\n",
      "Epoch: 3, Loss: 0.1470486306026578, Accuracy: 95.74305555555556%\n",
      "Epoch: 3, Loss: 0.11972265152260661, Accuracy: 95.84375%\n",
      "Epoch: 3, Loss: 0.12632695742882788, Accuracy: 95.88068181818183%\n",
      "Epoch: 3, Loss: 0.15436113554984332, Accuracy: 95.859375%\n",
      "Epoch: 3, Loss: 0.14399097309447825, Accuracy: 95.86538461538461%\n",
      "Epoch: 3, Loss: 0.12037418198771775, Accuracy: 95.93303571428572%\n",
      "Epoch: 3, Loss: 0.14235676418989895, Accuracy: 95.9375%\n",
      "Epoch: 3, Loss: 0.11693075906485319, Accuracy: 96.00390625%\n",
      "Epoch: 3, Loss: 0.11701151153072714, Accuracy: 96.05882352941177%\n",
      "Epoch: 3, Loss: 0.1209271795488894, Accuracy: 96.10416666666667%\n",
      "Epoch: 3, Loss: 0.11202185105998069, Accuracy: 96.1546052631579%\n",
      "Epoch: 3, Loss: 0.11378783685155212, Accuracy: 96.196875%\n",
      "Epoch: 3, Loss: 0.12120581123046577, Accuracy: 96.22321428571429%\n",
      "Epoch: 3, Loss: 0.113191341124475, Accuracy: 96.25852272727272%\n",
      "Epoch: 3, Loss: 0.13291565998457372, Accuracy: 96.26086956521739%\n",
      "Epoch: 3, Loss: 0.23714271562173964, Accuracy: 96.1328125%\n",
      "Epoch: 3, Loss: 0.233197132833302, Accuracy: 95.9675%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d462148ec2a348b4848ae05e13c18b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.1815065824612975, Accuracy: 94.3125%\n",
      "Epoch: 4, Loss: 0.13000142465345563, Accuracy: 95.375%\n",
      "Epoch: 4, Loss: 0.12617232226766645, Accuracy: 95.77083333333334%\n",
      "Epoch: 4, Loss: 0.11283955536782742, Accuracy: 96.109375%\n",
      "Epoch: 4, Loss: 0.16363862715661526, Accuracy: 95.89999999999999%\n",
      "Epoch: 4, Loss: 0.1067474174965173, Accuracy: 96.13541666666666%\n",
      "Epoch: 4, Loss: 0.14650901495479046, Accuracy: 96.08928571428571%\n",
      "Epoch: 4, Loss: 0.12933372266590595, Accuracy: 96.1484375%\n",
      "Epoch: 4, Loss: 0.14032363709993662, Accuracy: 96.13888888888889%\n",
      "Epoch: 4, Loss: 0.10912287363782525, Accuracy: 96.24374999999999%\n",
      "Epoch: 4, Loss: 0.1250154340453446, Accuracy: 96.2784090909091%\n",
      "Epoch: 4, Loss: 0.18257066479884088, Accuracy: 96.09895833333333%\n",
      "Epoch: 4, Loss: 0.14889267748221754, Accuracy: 96.07211538461539%\n",
      "Epoch: 4, Loss: 0.14122974935919047, Accuracy: 96.04017857142857%\n",
      "Epoch: 4, Loss: 0.15547442353330554, Accuracy: 96.00416666666666%\n",
      "Epoch: 4, Loss: 0.1304411625303328, Accuracy: 96.01171875%\n",
      "Epoch: 4, Loss: 0.15863597085699438, Accuracy: 95.94852941176471%\n",
      "Epoch: 4, Loss: 0.12599564030766486, Accuracy: 95.98611111111111%\n",
      "Epoch: 4, Loss: 0.1496659348346293, Accuracy: 95.96710526315789%\n",
      "Epoch: 4, Loss: 0.13647616884671152, Accuracy: 95.975%\n",
      "Epoch: 4, Loss: 0.11607749095186591, Accuracy: 96.02380952380952%\n",
      "Epoch: 4, Loss: 0.1421197535749525, Accuracy: 96.02272727272727%\n",
      "Epoch: 4, Loss: 0.13598809080198407, Accuracy: 96.04076086956522%\n",
      "Epoch: 4, Loss: 0.1252014202065766, Accuracy: 96.06510416666667%\n",
      "Epoch: 4, Loss: 0.12081078394316137, Accuracy: 96.095%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7aa90418c0140c798dcb4c506044569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.13243139388039707, Accuracy: 96.375%\n",
      "Epoch: 5, Loss: 0.14560538660734892, Accuracy: 96.03125%\n",
      "Epoch: 5, Loss: 0.14247733395546675, Accuracy: 95.95833333333333%\n",
      "Epoch: 5, Loss: 0.21314703173935412, Accuracy: 95.234375%\n",
      "Epoch: 5, Loss: 0.15644852874800563, Accuracy: 95.1375%\n",
      "Epoch: 5, Loss: 0.13537703832611442, Accuracy: 95.3125%\n",
      "Epoch: 5, Loss: 0.13043797798454762, Accuracy: 95.46428571428571%\n",
      "Epoch: 5, Loss: 0.13087120265699922, Accuracy: 95.59375%\n",
      "Epoch: 5, Loss: 0.13894293339923025, Accuracy: 95.63888888888889%\n",
      "Epoch: 5, Loss: 0.1251847102213651, Accuracy: 95.73125%\n",
      "Epoch: 5, Loss: 0.3613552219979465, Accuracy: 94.9375%\n",
      "Epoch: 5, Loss: 0.15554143078625202, Accuracy: 94.98958333333334%\n",
      "Epoch: 5, Loss: 0.13141772048547865, Accuracy: 95.0673076923077%\n",
      "Epoch: 5, Loss: 0.167375581972301, Accuracy: 95.03125%\n",
      "Epoch: 5, Loss: 0.14805990718305112, Accuracy: 95.09166666666667%\n",
      "Epoch: 5, Loss: 0.1373562161438167, Accuracy: 95.1640625%\n",
      "Epoch: 5, Loss: 0.14191289467737078, Accuracy: 95.21691176470588%\n",
      "Epoch: 5, Loss: 0.10944950837641955, Accuracy: 95.31944444444444%\n",
      "Epoch: 5, Loss: 0.13765565579757094, Accuracy: 95.36513157894737%\n",
      "Epoch: 5, Loss: 0.21020582494325935, Accuracy: 95.22812499999999%\n",
      "Epoch: 5, Loss: 0.13045416431501508, Accuracy: 95.2827380952381%\n",
      "Epoch: 5, Loss: 0.11851494525559246, Accuracy: 95.35511363636363%\n",
      "Epoch: 5, Loss: 0.13123678071424366, Accuracy: 95.40760869565217%\n",
      "Epoch: 5, Loss: 0.1468722623027861, Accuracy: 95.42708333333333%\n",
      "Epoch: 5, Loss: 0.12894947844557464, Accuracy: 95.465%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(dl)):\n",
    "        _, labels, tokens = data\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        tokens = tokens.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mask = pad_token_mask(tokens)\n",
    "        outputs = model(tokens, mask=None)\n",
    "        loss = crit(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # Count correct predictions\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = (total_correct / total_samples) * 100\n",
    "        # calculate accuracy\n",
    "        if i % 100 == 99:\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1}, Loss: {running_loss / 100}, Accuracy: {accuracy}%\"\n",
    "            )\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn): ScaledDotProductAttention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 96.19%\n",
      "Average loss on the test data: 0.1328\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():  # Important to use torch.no_grad() to save memory and computations\n",
    "    for batch in test_dl:\n",
    "        _, labels, tokens = batch\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        tokens = tokens.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(tokens)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Convert outputs probabilities to predicted class (0 or 1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Count total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_loss = total_loss / len(test_dl)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"Accuracy of the model on the test data: {accuracy:.2f}%\")\n",
    "print(f\"Average loss on the test data: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
