{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dyck_k_generator import constants, checker, generator\n",
    "from transformer import dataset, transformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'()[]{}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = ''.join([''.join((key, value)) for key, value in list(constants.BRACKETS.items())[:k]])\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformerConfig:\n",
       "{'act_fn': 'relu',\n",
       " 'attention_dir': 'bidirectional',\n",
       " 'attn_only': False,\n",
       " 'attn_types': None,\n",
       " 'checkpoint_index': None,\n",
       " 'checkpoint_label_type': None,\n",
       " 'checkpoint_value': None,\n",
       " 'd_head': 28,\n",
       " 'd_mlp': 56,\n",
       " 'd_model': 56,\n",
       " 'd_vocab': 9,\n",
       " 'd_vocab_out': 2,\n",
       " 'default_prepend_bos': True,\n",
       " 'device': 'cpu',\n",
       " 'dtype': torch.float32,\n",
       " 'eps': 1e-05,\n",
       " 'final_rms': False,\n",
       " 'from_checkpoint': False,\n",
       " 'gated_mlp': False,\n",
       " 'init_mode': 'gpt2',\n",
       " 'init_weights': True,\n",
       " 'initializer_range': 0.10690449676496976,\n",
       " 'model_name': 'custom',\n",
       " 'n_ctx': 102,\n",
       " 'n_devices': 1,\n",
       " 'n_heads': 2,\n",
       " 'n_key_value_heads': None,\n",
       " 'n_layers': 3,\n",
       " 'n_params': 56448,\n",
       " 'normalization_type': 'LN',\n",
       " 'original_architecture': None,\n",
       " 'parallel_attn_mlp': False,\n",
       " 'positional_embedding_type': 'standard',\n",
       " 'post_embedding_ln': False,\n",
       " 'rotary_adjacent_pairs': False,\n",
       " 'rotary_base': 10000,\n",
       " 'rotary_dim': None,\n",
       " 'scale_attn_by_inverse_layer_idx': False,\n",
       " 'seed': None,\n",
       " 'tokenizer_name': None,\n",
       " 'tokenizer_prepends_bos': None,\n",
       " 'trust_remote_code': False,\n",
       " 'use_attn_in': False,\n",
       " 'use_attn_result': True,\n",
       " 'use_attn_scale': True,\n",
       " 'use_hook_mlp_in': False,\n",
       " 'use_hook_tokens': True,\n",
       " 'use_local_attn': False,\n",
       " 'use_split_qkv_input': False,\n",
       " 'window_size': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = transformer.generate_config(\n",
    "    n_ctx=102,\n",
    "    d_model=56,\n",
    "    d_head=28,\n",
    "    n_heads=2,\n",
    "    d_mlp=56,\n",
    "    n_layers=3,\n",
    "    attention_dir='bidirectional',\n",
    "    act_fn='relu',\n",
    "    d_vocab=len(VOCAB) + 3,\n",
    "    d_vocab_out=2,\n",
    "    use_attn_result=True,\n",
    "    device=device,\n",
    "    use_hook_tokens=True\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer.generate_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (hook_tokens): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-2): 3 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.dataset import DyckLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 samples from data/dyck-1_1000-samples_100-len_p07.jsonl\n"
     ]
    }
   ],
   "source": [
    "dataset = DyckLanguageDataset('data/dyck-1_1000-samples_100-len_p07.jsonl', VOCAB).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('((()(()())(()())()))(',\n",
       " tensor(False),\n",
       " tensor([0, 3, 3, 3, 4, 3, 3, 4, 3, 4, 4, 3, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 2, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "Item = namedtuple('Item', field_names=[\"string\", \"target\", \"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = Item(dataset[0][0], dataset[0][1], dataset[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 3, 3, 4, 3, 3, 4, 3, 4, 4, 3, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 2, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (hook_tokens): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-2): 3 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n",
      "torch.Size([1, 102])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dl):\n",
    "    print(batch[2].shape)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.train import train, HookedTransformerTrainConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerTrainConfig(\n",
    "    num_epochs=1,\n",
    "    batch_size=1,\n",
    "    lr=1e-4,\n",
    "    seed=42,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bc84e896cc4d66a46de1737658745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb40542682134d47b83fd5e6f51b5daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer-checker/lib/python3.10/site-packages/transformer_lens/train.py:123\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, config, dataset)\u001b[0m\n\u001b[1;32m    121\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader)):\n\u001b[0;32m--> 123\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    124\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model(tokens, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "model = train(model, cfg, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
